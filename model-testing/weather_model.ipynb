{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7cfff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import pygrib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "616a5af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read GRIB file and extract data\n",
    "def read_grib_file(grib_file):\n",
    "    grbs = pygrib.open(grib_file)\n",
    "    grb = grbs.select()[0]\n",
    "\n",
    "    # Extract the data from the GRIB message\n",
    "    data = grb.values\n",
    "    latitudes, longitudes = grb.latlons()\n",
    "\n",
    "    grbs.close()\n",
    "\n",
    "    return data, latitudes, longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "103e6c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    # Normalize data (optional, based on your requirements)\n",
    "    normalized_data = (data - np.mean(data)) / np.std(data)\n",
    "\n",
    "    return normalized_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0984574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build and train the CNN model\n",
    "def build_cnn_model(input_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))  # Output layer for regression\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01ebea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder_path):\n",
    "    subfolders = ['000', '012']\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for subfolder in subfolders:\n",
    "        subfolder_path = os.path.join(folder_path, subfolder)\n",
    "        files = os.listdir(subfolder_path)\n",
    "\n",
    "        for file in files:\n",
    "            grib_file_12h = os.path.join(subfolder_path, file)\n",
    "            grib_file_0h = os.path.join(folder_path, '000', file)\n",
    "\n",
    "            if os.path.isfile(grib_file_12h) and os.path.isfile(grib_file_0h):\n",
    "                # Read and preprocess the data\n",
    "                data_12h, latitudes, longitudes = read_grib_file(grib_file_12h)\n",
    "                data_0h, _, _ = read_grib_file(grib_file_0h)\n",
    "\n",
    "                # Preprocess the data\n",
    "                X.append(preprocess_data(data_12h))\n",
    "                Y.append(preprocess_data(data_0h))\n",
    "\n",
    "    return np.array(X), np.array(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8ba1569",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../download'  # Folder path containing the GRIB files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4400d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "X, Y = load_data(data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb3354d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640\n",
      "640\n"
     ]
    }
   ],
   "source": [
    "print(len(Y))\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c3e9704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.45527329 -1.45527329 -1.45527329 ... -1.45527329 -1.45527329\n",
      "  -1.45527329]\n",
      " [-1.45605818 -1.45587953 -1.45569502 ... -1.45660291 -1.45642133\n",
      "  -1.45623975]\n",
      " [-1.45241781 -1.45203122 -1.45164756 ... -1.45358343 -1.45319098\n",
      "  -1.4528044 ]\n",
      " ...\n",
      " [-0.8939508  -0.89369015 -0.89342364 ... -0.89470641 -0.8944604\n",
      "  -0.89420853]\n",
      " [-0.85844038 -0.85831737 -0.85819144 ... -0.85880061 -0.85868346\n",
      "  -0.85856338]\n",
      " [-0.82595529 -0.82595529 -0.82595529 ... -0.82595529 -0.82595529\n",
      "  -0.82595529]]\n"
     ]
    }
   ],
   "source": [
    "print(X[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5bb9e345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93813a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 361, 720)\n",
      "(512, 361, 720)\n",
      "(128, 361, 720)\n",
      "(128, 361, 720)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of X_train for debugging\n",
    "print(X_train.shape)  \n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a93bd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CNN model\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model = build_cnn_model(input_shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0c4996e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(361, 720)\n"
     ]
    }
   ],
   "source": [
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5759cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/data/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/data/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/data/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/data/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/data/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"/home/data/.local/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/data/.local/lib/python3.10/site-packages/keras/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/data/.local/lib/python3.10/site-packages/keras/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/data/.local/lib/python3.10/site-packages/keras/losses.py\", line 1470, in mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 4 and 361 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](sequential/dense_1/BiasAdd, IteratorGetNext:1)' with input shapes: [4,1], [4,361,720].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filemjjcipzx.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/data/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/data/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/data/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/data/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/data/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"/home/data/.local/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/data/.local/lib/python3.10/site-packages/keras/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/data/.local/lib/python3.10/site-packages/keras/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/data/.local/lib/python3.10/site-packages/keras/losses.py\", line 1470, in mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 4 and 361 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](sequential/dense_1/BiasAdd, IteratorGetNext:1)' with input shapes: [4,1], [4,361,720].\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31ea2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions (replace X_test with your test data)\n",
    "#predictions = model.predict(X_test)\n",
    "#predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce673604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform any further processing or analysis with the predictions\n",
    "# Hereafter, you can do whatever you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14aa2f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/data/detectives/data-detectives\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a921f31a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
